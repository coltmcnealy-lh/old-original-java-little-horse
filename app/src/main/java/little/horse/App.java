/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package little.horse;

import java.util.Collections;
import java.util.Properties;
import java.util.regex.Pattern;

import org.apache.kafka.clients.admin.NewTopic;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.Topology;

import little.horse.api.APIStreamsContext;
import little.horse.api.TaskDefTopology;
import little.horse.api.WFSpecDeployer;
import little.horse.api.WFSpecTopology;
import little.horse.lib.Config;
import little.horse.lib.Constants;
import little.horse.lib.NullWFEventActor;
import little.horse.lib.WFEventProcessorActor;
import little.horse.lib.WFRunTopology;
import little.horse.lib.WFSpecSchema;
import little.horse.lib.kafkaStreamsSerdes.WFSpecDeSerializer;


class FrontendAPIApp {
    private static void createKafkaTopics(Config config) {
        int partitions = 1;
        short replicationFactor = 1;

        String[] topics = {
            config.getWFSpecActionsTopic(),
            config.getWFSpecTopic(),
            config.getWFSpecIntermediateTopic(),
            config.getTaskDefNameKeyedTopic(),
            config.getTaskDefTopic()
        };
        for (String topicName : topics) {
            NewTopic newTopic = new NewTopic(topicName, partitions, replicationFactor);
            config.createKafkaTopic(newTopic);
        }
    }

    public static void run() {
        Config config = null;
        config = new Config();

        FrontendAPIApp.createKafkaTopics(config);

        WFSpecTopology wfSpecTopology = new WFSpecTopology(config);
        Topology topology = wfSpecTopology.build();
        KafkaStreams wfSpecStreams = new KafkaStreams(topology, config.getStreamsConfig(
            "wfSpec"
        ));

        TaskDefTopology taskDefTopologyBuilder = new TaskDefTopology(config);
        Topology taskDefTopology = taskDefTopologyBuilder.getTopology();
        KafkaStreams taskDefStreams = new KafkaStreams(
            taskDefTopology,
            config.getStreamsConfig("taskDef")
        );

        WFEventProcessorActor actor = new NullWFEventActor();

        WFRunTopology wfRunTopologyBuilder = new WFRunTopology(
            config, config.getAllWFRunTopicsPattern(), actor
        );
        Topology wfRunTopology = wfRunTopologyBuilder.getTopology();
        KafkaStreams wfRunStreams = new KafkaStreams(
            wfRunTopology,
            config.getStreamsConfig("wfRunAPIStreams")
        );

        APIStreamsContext context = new APIStreamsContext(
            wfSpecStreams,
            taskDefStreams,
            wfRunStreams
        );
        context.setWFSpecStoreName(wfSpecTopology.getStoreName());
        context.setTaskDefGuidStoreName(Constants.TASK_DEF_GUID_STORE);
        context.setTaskDefNameStoreName(Constants.TASK_DEF_NAME_STORE);
        context.setWFRunStoreName(Constants.WF_RUN_STORE);

        LittleHorseAPI lapi = new LittleHorseAPI(config, context);

        Properties props = config.getConsumerConfig("wfSpecDeployer");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, WFSpecDeSerializer.class.getName());

        KafkaConsumer<String, WFSpecSchema> consumer = new KafkaConsumer<>(
            props
        );
        consumer.subscribe(Collections.singletonList(config.getWFSpecActionsTopic()));
        WFSpecDeployer deployer = new WFSpecDeployer(consumer, config);
        Thread deployerThread = new Thread(() -> deployer.run());

        Runtime.getRuntime().addShutdownHook(new Thread(deployer::shutdown));
        Runtime.getRuntime().addShutdownHook(new Thread(config::cleanup));
        Runtime.getRuntime().addShutdownHook(new Thread(lapi::cleanup));
        Runtime.getRuntime().addShutdownHook(new Thread(wfSpecStreams::close));
        Runtime.getRuntime().addShutdownHook(new Thread(taskDefStreams::close));
        Runtime.getRuntime().addShutdownHook(new Thread(wfRunStreams::close));

        deployerThread.start();
        wfSpecStreams.start();
        taskDefStreams.start();
        lapi.run();
    }
}


class DaemonApp {
    public static void run() {
        Config config = new Config();

        // just need to set up the topology and run it.
        WFEventProcessorActor actor = new NullWFEventActor();

        Pattern pattern = Pattern.compile(config.getNodeName());
        WFRunTopology wfRunTopologyBuilder = new WFRunTopology(
            config, pattern, actor
        );
        KafkaStreams streams = new KafkaStreams(
            wfRunTopologyBuilder.getTopology(),
            config.getStreamsConfig(config.getNodeName())
        );
        Runtime.getRuntime().addShutdownHook(new Thread(streams::close));
        streams.start();
    }
}

public class App {
    public static void main(String[] args) {
        if (args[0].equals("daemon")) {
            DaemonApp.run();
        } else if (args[0].equals("api")) {
            FrontendAPIApp.run();
        } else {
            System.out.println(
                "Please specify either 'api' or 'daemon' commandline arg"
            );
        }
    }
}
