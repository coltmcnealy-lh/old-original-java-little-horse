/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package little.horse;

import java.lang.reflect.Field;
import java.util.regex.Pattern;

import org.apache.kafka.clients.admin.NewTopic;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.Topology;

import little.horse.api.LittleHorseAPI;
import little.horse.api.runtime.WFRunTopology;
import little.horse.common.Config;
import little.horse.common.objects.DigestIgnore;

class FrontendAPIApp {
    private static void createKafkaTopics(Config config) {
        int partitions = 1;
        short replicationFactor = 1;

        String[] topics = {
            config.getWFSpecActionsTopic(),
            config.getWFSpecTopic(),
            config.getWFSpecIntermediateTopic(),
            config.getTaskDefNameKeyedTopic(),
            config.getTaskDefTopic(),
            config.getWFSpecNameKeyedTopic(),
            config.getExternalEventDefNameKeyedTopic(),
            config.getWFRunTopic(),
            config.getExternalEventDefTopic()
        };
        for (String topicName : topics) {
            NewTopic newTopic = new NewTopic(topicName, partitions, replicationFactor);
            config.createKafkaTopic(newTopic);
        }
    }

    /**
     * Does three things:
     * 1. Sets up a KafkaStreams topology for processing WFSpec, TaskDef, and WFRun updates.
     * 2. Sets up a LittleHorseAPI to respond to metadata control requests.
     * 3. Sets up a listener for new WFSpecs that deploys them to kubernetes (if necessary).
     */
    public static void run() {
        Config config = null;
        config = new Config();

        FrontendAPIApp.createKafkaTopics(config);
        Topology topology = new Topology();

        // TaskDefTopology.addStuff(topology, config);
        // WFSpecTopology.addStuff(topology, config);
        // ExternalEventDefTopology.addStuff(topology, config);

        WFRunTopology.addStuff(
            topology,
            config,
            Pattern.compile(config.getWFRunTopic())
        );

        KafkaStreams streams = new KafkaStreams(topology, config.getStreamsConfig());
        LittleHorseAPI lapi = new LittleHorseAPI(config, streams);

        Runtime.getRuntime().addShutdownHook(new Thread(config::cleanup));
        Runtime.getRuntime().addShutdownHook(new Thread(lapi::cleanup));
        Runtime.getRuntime().addShutdownHook(new Thread(streams::close));

        streams.start();
        lapi.run();
    }
}


class Thing {
    // @IncludeInDigest
    public String mystring;
    @DigestIgnore
    public Object foobar;

    @DigestIgnore
    public int myint = 123;

    public void printDigest() throws IllegalAccessException {
        for (Field field: this.getClass().getDeclaredFields()) {
            field.setAccessible(true);
            if (field.isAnnotationPresent(DigestIgnore.class)) {
                System.out.println(field.get(this).toString());
            }
        }
    }
}

public class App {
    public static void main(String[] args) {
        if (args.length > 0 && args[0].equals("api")) {
            System.out.println("running the app");
            FrontendAPIApp.run();
        } else {
            System.out.println("Nothing to do");
        }
    }
}
