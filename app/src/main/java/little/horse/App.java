/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package little.horse;

import java.util.Collections;
import java.util.Properties;

import org.apache.kafka.clients.admin.NewTopic;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.Topology;

import little.horse.api.APIStreamsContext;
import little.horse.api.TaskDefTopology;
import little.horse.api.WFSpecDeployer;
import little.horse.api.WFSpecTopology;
import little.horse.lib.Config;
import little.horse.lib.Constants;
import little.horse.lib.WFSpec.WFSpecSchema;
import little.horse.lib.WFSpec.kafkaStreamsSerdes.WFSpecDeSerializer;


class FrontendAPIApp {
    private static void createKafkaTopics(Config config) {
        int partitions = 1;
        short replicationFactor = 1;

        String[] topics = {
            config.getWFSpecActionsTopic(),
            config.getWFSpecTopic(),
            config.getWFSpecIntermediateTopic(),
            config.getTaskDefNameKeyedTopic(),
            config.getTaskDefTopic()
        };
        for (String topicName : topics) {
            NewTopic newTopic = new NewTopic(topicName, partitions, replicationFactor);
            config.createKafkaTopic(newTopic);
        }
    }

    public static void run() {
        Config config = null;
        config = new Config();

        FrontendAPIApp.createKafkaTopics(config);

        WFSpecTopology wfSpecTopology = new WFSpecTopology(config);
        Topology topology = wfSpecTopology.build();
        KafkaStreams wfSpecStreams = new KafkaStreams(topology, config.getStreamsConfig(
            "wfSpec"
        ));

        TaskDefTopology taskDefTopologyBuilder = new TaskDefTopology(config);
        Topology taskDefTopology = taskDefTopologyBuilder.getTopology();
        KafkaStreams taskDefStreams = new KafkaStreams(
            taskDefTopology,
            config.getStreamsConfig("taskDef")
        );

        APIStreamsContext context = new APIStreamsContext(wfSpecStreams, taskDefStreams);
        context.setWFSpecStoreName(wfSpecTopology.getStoreName());
        context.setTaskDefGuidStoreName(Constants.TASK_DEF_GUID_STORE);
        context.setTaskDefNameStoreName(Constants.TASK_DEF_NAME_STORE);

        LittleHorseAPI lapi = new LittleHorseAPI(config, context);

        Properties props = config.getConsumerConfig("wfSpecDeployer");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, WFSpecDeSerializer.class.getName());

        KafkaConsumer<String, WFSpecSchema> consumer = new KafkaConsumer<>(
            props
        );
        consumer.subscribe(Collections.singletonList(config.getWFSpecActionsTopic()));
        WFSpecDeployer deployer = new WFSpecDeployer(consumer, config);
        Thread deployerThread = new Thread(() -> deployer.run());

        Runtime.getRuntime().addShutdownHook(new Thread(deployer::shutdown));
        Runtime.getRuntime().addShutdownHook(new Thread(config::cleanup));
        Runtime.getRuntime().addShutdownHook(new Thread(lapi::cleanup));
        Runtime.getRuntime().addShutdownHook(new Thread(wfSpecStreams::close));
        Runtime.getRuntime().addShutdownHook(new Thread(taskDefStreams::close));

        deployerThread.start();
        wfSpecStreams.start();
        taskDefStreams.start();
        lapi.run();
    }
}

class DaemonApp {
    public static void run() {}
}

class CollectorApp {
    public static void run() {}
}

public class App {
    public static void main(String[] args) {
        if (args[0] == "daemon") {
            DaemonApp.run();
        } else if (args[0] == "collector") {
            CollectorApp.run();
        } else {
            FrontendAPIApp.run();
        }
    }
}
